{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mDre_apkpure\u001b[m\u001b[m/    \u001b[1m\u001b[34mdata\u001b[m\u001b[m/           \u001b[1m\u001b[34mmodel\u001b[m\u001b[m/          \u001b[1m\u001b[34msource\u001b[m\u001b[m/\r\n",
      "Untitled.ipynb  \u001b[1m\u001b[34mmeasures\u001b[m\u001b[m/       \u001b[1m\u001b[34mresult\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "prob1 = []\n",
    "prob2 = []\n",
    "# threshold = float(sys.argv[2])\n",
    "threshold = 0.5\n",
    "pred1 = []\n",
    "pred2 = []\n",
    "\n",
    "for val in result:\n",
    "    label.append(val[0])\n",
    "    prob1.append(val[1])\n",
    "    prob2.append(val[2])\n",
    "    if val[1] >= threshold:\n",
    "        pred1.append(1)\n",
    "    else:\n",
    "        pred1.append(0)\n",
    "    if val[2] >= threshold:\n",
    "        pred2.append(1)\n",
    "    else:\n",
    "        pred2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "label = json.load(open('result/true.json'))\n",
    "prob1 = json.load(open('result/clf_p.json'))\n",
    "prob2 = json.load(open('result/clf_r.json'))\n",
    "threshold = 0.7\n",
    "pred1 = []\n",
    "pred2 = []\n",
    "for ind, val in enumerate(label):\n",
    "    if prob1[ind][1]>= threshold:\n",
    "        pred1.append(1)\n",
    "    else:\n",
    "        pred1.append(0)\n",
    "    if prob2[ind][1]>= threshold:\n",
    "        pred2.append(1)\n",
    "    else:\n",
    "        pred2.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first model .........\n",
      "    confusion matrix    \n",
      "[[1042  211]\n",
      " [   9 1084]]\n",
      "detection rate: 0.991765782251\n",
      "false positive: 0.16839584996\n",
      "precision: 0.837066\n",
      "recall: 0.991766\n",
      "Accuracy: 0.906223\n",
      "F1: 0.907873\n",
      "second model .........\n",
      "[[1236   17]\n",
      " [  36 1057]]\n",
      "detection rate: 0.967063129003\n",
      "false positive: 0.0135674381484\n",
      "precision: 0.984171\n",
      "recall: 0.967063\n",
      "Accuracy: 0.977408\n",
      "F1: 0.975542\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "result = json.load(open('result/test_result.json'))\n",
    "\n",
    "def precision(metric):\n",
    "    return float(metric[1][1]) / (metric[1][1] + metric[0][1])\n",
    "\n",
    "def recall(metric):\n",
    "    return float(metric[1][1]) / (metric[1][1] + metric[1][0])\n",
    "\n",
    "def Accuracy(metric):\n",
    "    return float( metric[0][0] + metric[1][1]) / (metric[1][1]+metric[1][0] + metric[0][0] + metric[0][1])\n",
    "\n",
    "def Fone(pre,recall):\n",
    "    return 2 * pre * recall / ( pre + recall )\n",
    "\n",
    "\n",
    "## confusion matrix\n",
    "print('first model .........')\n",
    "print('    confusion matrix    ')\n",
    "a = confusion_matrix(label,pred1)\n",
    "print(a)\n",
    "print('detection rate: %s' % (float(a[1][1]) / ( a[1][1]+ a[1][0]) ))\n",
    "print('false positive: %s' % (float(a[0][1]) / ( a[0][1]+ a[0][0]) ) )\n",
    "print('precision: %f' % precision(a))\n",
    "# print( precision(a))\n",
    "print('recall: %f' % recall(a))\n",
    "# print( recall(a) )\n",
    "print('Accuracy: %f' % Accuracy(a))\n",
    "# print( Accuracy(a))\n",
    "print('F1: %f'  % Fone(precision(a),recall(a)))\n",
    "\n",
    "\n",
    "print('second model .........')\n",
    "a = confusion_matrix(label,pred2)\n",
    "print(a)\n",
    "print('detection rate: %s' % (float(a[1][1]) / ( a[1][1]+ a[1][0]) ))\n",
    "print('false positive: %s' % (float(a[0][1]) / ( a[0][1]+ a[0][0]) ) )\n",
    "print('precision: %f' % precision(a))\n",
    "# print( precision(a))\n",
    "print('recall: %f' % recall(a))\n",
    "# print( recall(a) )\n",
    "print('Accuracy: %f' % Accuracy(a))\n",
    "# print( Accuracy(a))\n",
    "print('F1: %f'  % Fone(precision(a),recall(a)))\n",
    "# print(Fone(precision(a),recall(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.185657370518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9935956084172004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(label,pred1)\n",
    "\n",
    "plt.plot(fpr, tpr, 'g-', lw=2, label = 'GCN: auc = %f' % auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(label,pred2)\n",
    "plt.plot(fpr, tpr, 'r-', lw=2, label = 'SVM: auc = %f' % auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
