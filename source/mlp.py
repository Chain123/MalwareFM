import numpy as np
from scipy import sparse
import json
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier as mlp
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
import sys
import os
from random import shuffle
import argparse
import math
# import pickle
from sklearn.externals import joblib
import timeit


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--feature",
	                    help="sparse matrix stores embedded feature")
parser.add_argument("-l", "--label",									## this is only for non-sparse label vector case
	                    help="JSON file label of all samples")
parser.add_argument("-t", "--train",
                            help="if train is true, will do cross validation for model selection")
parser.add_argument("-p", "--proba",
    		            help="if proba is true, load the saved model and test, get predicted probability on test data set and stored")
args = parser.parse_args()
loader1 = np.load(args.feature)
feature = sparse.csr_matrix((loader1['data'],loader1['indices'],loader1['indptr']),shape=loader1['shape'])

label = json.load(open(args.label))
label2 = np.array(label).reshape(len(label))

# number_of_train = int(len(label2)*0.8)
# number_of_test = len(label2) - number_of_train
# start = 1000
# train_feature = feature[0:number_of_train]
# train_label = label2[0:number_of_train]

# test_feature = feature[number_of_train:]
# test_label = label2[number_of_train: ]

# parameter selection
if args.train:
    model = mlp()
    tuned_params=[{'hidden_layer_sizes':[(100,),(150,),(50,)],'activation': ['relu','logistic'],'solver': ['adam','sgd'] }]
    scores=['precision','recall']

    for score in scores:
        print("parameter selecting with score %s ....." % score)
        print(" ")
        clf = GridSearchCV(model,tuned_params,scoring = score)
        clf.fit(feature,label2)
        print(" ")
        print('Best params: ')
        print(clf.best_params_)
        print(" ")
        print('results: ')
        print(clf.cv_results_)
else: 
	## train on best parameter set
    if os.path.exists('../model/mlp_p.pkl'):
        print('model exists, loading from ../model folder')
        clf_p = joblib.load('../model/mlp_p.pkl')
        clf_r = joblib.load('../model/mlp_r.pkl')
    else:
        mlp_p = mlp(hidden_layer_sizes=(100,), activation='relu', solver='sgd')
#        mlp_r = mlp(hidden_layer_sizes=(100,), activation='relu', solver='sgd')
        print("training....")
        mlp_p.fit(feature,label)
#        mlp_r.fit(feature,label)
        ##  save model
        print('saving models')
        joblib.dump(clf_p,'../model/mlp_p.pkl') 
#        joblib.dump(clf_r,'../model/mlp_r.pkl') 
        print(len(label))
if args.proba:
    print(len(label2))
    prediction_p = list(np.array(mlp_p.predict_proba(feature)))
    prediction_r = list(np.array(mlp_r.predict_proba(feature)))
    prob_p = []
    prob_r = []
    #for val in prediction_p:
    
    print('saving test result')
    final_result = zip(label2, list(prediction_p), list(prediction_r))
    with open('../result/mlp_test_result.json','w') as myfile:
        json.dump(final_result,myfile)    
print("Done!")

